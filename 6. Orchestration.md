# Building End to End Orchestration

In this section, we will perform the following steps of the End-to-End ELT Pipeline.

**Step 6: Orchestration**

- **Tool:** Dagster
- **Action:** Dagster acts as the "conductor" for the entire pipeline. It automates and sequences all the above steps. It first triggers Extract-Load, then Validation, transformation and finally testing, ensuring each step runs successfully and in the correct order.
- **Output:** End to end data pipeline can now be orchestrated to run from start to end and handle incremental updates.

`Dagster` is a data orchestrator for machine learning, analytics, and ETL. It lets you define pipelines in terms of the data flow between reusable, logical components, then test locally and run anywhere. With a unified view of pipelines and the assets they produce, Dagster can schedule and orchestrate Pandas, Spark, SQL, or anything else that Python can invoke.

### Create a Dagster Project

We need to use `dagster_environment.yml` file in the [environment folder](https://github.com/su-ntu-ctp/5m-data-2.1-intro-big-data-eng/tree/main/environments) in the repository of module 2.1. Create the environment and run the following command to activate the environment:

```bash
conda activate dagster
```

Also make sure you exit the dbt folder `resale_flat` using command `cd ..`

To create a new Dagster project:

```bash
dagster project scaffold --name dagster-orchestration
```

After running this command, you should see a new directory called `dagster-orchestration` in your current directory. This directory contains the files that make up your Dagster project. 

Then switch into the folder by:

```bash
cd dagster-orchestration
```

### Introduction to Software-Defined Assets, Pipelines, Jobs and Schedule

In Dagster, the main way to create data pipelines is by writing `Software-Defined Assets` (SDA). You can connect assets together (that depend on each other) to form a pipeline. An asset is a logical unit of data that can be produced or consumed by a pipeline. Assets can be any type of object, e.g.

- A database table or view
- A file, such as in your local machine or object storage like Google Cloud Storage
- A machine learning model



Create folder call assets inside dagster-orchestration\dagster_orchestration

-If there is no __init__.py file inside dagster-orchestration\dagster_orchestration\assets, create one.

-Create dbtpipeline.py 

-Create ingestion_pipeline.py

-Create meltano_pipeline.py

Then go to dagster-orchestration\dagster_orchestration

-If there is no __init__.py file under dagster-orchestration\dagster_orchestration, create one.

-Create definitios.py

Go to path dagster-orchestration and run

```
dagster dev -m dagster_orchestration.definitions
```